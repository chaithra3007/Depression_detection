{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.optim as optim\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=np.load(\"/mnt/sd1/jhansi/interns/chaithra/MS/sal_project/Features/train/train_text_feats.npz\", allow_pickle=True)['text_features']\n",
    "b= np.load(\"/mnt/sd1/jhansi/interns/chaithra/MS/sal_project/Features/test/test__text_feats.npz\", allow_pickle=True)['text_features']\n",
    "\n",
    "t1=[np.squeeze(np.array(text), axis=1) for text in a]\n",
    "t2 = [\n",
    "    np.squeeze(np.array(text), axis=1)\n",
    "    for text in b\n",
    "    if len(np.array(text).shape) == 3\n",
    "]\n",
    "\n",
    "train_text_features=t1\n",
    "test_text_features=t2\n",
    "train_labels = np.load(\"/mnt/sd1/jhansi/interns/chaithra/MS/sal_project/Features/train/train_c_labels.npz\", allow_pickle=True)['labels']\n",
    "test_labels = np.load(\"/mnt/sd1/jhansi/interns/chaithra/MS/sal_project/Features/test/test_c_labels.npz\", allow_pickle=True)['labels']\n",
    "\n",
    "# Remove labels at indices 24 and 25\n",
    "indices_to_remove = [24, 25]\n",
    "test_labels = np.delete(test_labels, indices_to_remove, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([104, 69, 1024])\n",
      "torch.Size([30, 63, 1024])\n"
     ]
    }
   ],
   "source": [
    "train_text_features_tensors = [torch.tensor(f) for f in train_text_features]\n",
    "# Now pad the sequences to ensure uniform length\n",
    "padded_train_text_features = pad_sequence(train_text_features_tensors, batch_first=True)\n",
    "\n",
    "# Print the shape of the padded tensor\n",
    "print(padded_train_text_features.shape)\n",
    "\n",
    "test_text_features_tensors = [torch.tensor(f) for f in test_text_features]\n",
    "padded_test_text_features = pad_sequence(test_text_features_tensors, batch_first=True)\n",
    "print(padded_test_text_features.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = np.array(train_labels, dtype=np.int64)\n",
    "test_labels = np.array(test_labels, dtype=np.int64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Assuming train_text_features and test_text_features have been padded earlier\n",
    "class textDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, text_features, labels):\n",
    "        self.text_features = text_features\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.text_features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # No need to wrap the features and labels again with torch.tensor\n",
    "        return self.text_features[idx], torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "\n",
    "# Create train and test datasets\n",
    "train_dataset = textDataset(padded_train_text_features, train_labels)\n",
    "test_dataset = textDataset(padded_test_text_features, test_labels)\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([104, 70656])\n",
      "torch.Size([148, 69, 1024])\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "labels_t = np.squeeze(train_labels)  # Converts to 1D if it's in shape (n_samples, 1)\n",
    "\n",
    "# Flatten the audio features to 2D (n_samples, sequence_length * num_features)\n",
    "flattened_train_text_features = padded_train_text_features.view(padded_train_text_features.size(0), -1)\n",
    "print(flattened_train_text_features.shape)  # Should be [n_samples, 63 * 256]\n",
    "\n",
    "# Apply SMOTE to balance the data\n",
    "smote = SMOTE(random_state=42)\n",
    "balanced_features, balanced_labels = smote.fit_resample(flattened_train_text_features.numpy(), labels_t)\n",
    "\n",
    "# Convert the balanced features and labels to PyTorch tensors\n",
    "balanced_features = torch.tensor(balanced_features).to(device)\n",
    "balanced_labels = torch.tensor(balanced_labels).to(device)\n",
    "# Check the current total size and calculate time steps\n",
    "num_samples = balanced_features.size(0)\n",
    "num_features = 1024  # Assuming this is fixed\n",
    "time_steps = balanced_features.size(1) // num_features\n",
    "\n",
    "# Reshape to 3D\n",
    "balanced_features = balanced_features.view(num_samples, time_steps, num_features)\n",
    "print(balanced_features.shape)  # Verify the shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Assuming train_text_features and test_text_features have been padded earlier\n",
    "class textDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, text_features, labels):\n",
    "        self.text_features = text_features\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.text_features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # No need to wrap the features and labels again with torch.tensor\n",
    "        return self.text_features[idx], torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "\n",
    "# Create train and test datasets\n",
    "train_dataset = textDataset(balanced_features, balanced_labels)\n",
    "test_dataset = textDataset(padded_test_text_features, test_labels)\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextBiLSTM(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(TextBiLSTM, self).__init__()\n",
    "        self.num_classes = config['num_classes']\n",
    "        self.learning_rate = config['learning_rate']\n",
    "        self.dropout = config['dropout']\n",
    "        self.hidden_dims = config['hidden_dims']\n",
    "        self.rnn_layers = config['rnn_layers']\n",
    "        self.embedding_size = config['embedding_size']\n",
    "        self.bidirectional = config['bidirectional']\n",
    "\n",
    "        self.build_model()\n",
    "        self.init_weight()\n",
    "        \n",
    "    def init_weight(net):\n",
    "        for name, param in net.named_parameters():\n",
    "            if 'ln' not in name:\n",
    "                if 'bias' in name:\n",
    "                    nn.init.constant_(param, 0.0)\n",
    "                elif 'weight' in name:\n",
    "                    nn.init.xavier_uniform_(param)\n",
    "\n",
    "    def build_model(self):\n",
    "        # attention layer\n",
    "        self.attention_layer = nn.Sequential(\n",
    "            nn.Linear(self.hidden_dims, self.hidden_dims),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        # self.attention_weights = self.attention_weights.view(self.hidden_dims, 1)\n",
    "\n",
    "        # 双层lstm\n",
    "        self.lstm_net = nn.LSTM(self.embedding_size, self.hidden_dims,\n",
    "                                num_layers=self.rnn_layers, dropout=self.dropout,\n",
    "                                bidirectional=self.bidirectional)\n",
    "                \n",
    "        # FC层\n",
    "        # self.fc_out = nn.Linear(self.hidden_dims, self.num_classes)\n",
    "        self.fc_out = nn.Sequential(\n",
    "            # nn.Dropout(self.dropout),\n",
    "            nn.Linear(self.hidden_dims, self.hidden_dims),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(self.dropout),\n",
    "            nn.Linear(self.hidden_dims, self.num_classes),\n",
    "            # nn.ReLU(),\n",
    "            nn.Softmax(dim=1),\n",
    "        )\n",
    "\n",
    "        self.ln1 = nn.LayerNorm(self.embedding_size)\n",
    "        self.ln2 = nn.LayerNorm(self.hidden_dims)\n",
    "\n",
    "        \n",
    "    def attention_net_with_w(self, lstm_out, lstm_hidden):\n",
    "        '''\n",
    "        :param lstm_out:    [batch_size, len_seq, n_hidden * 2]\n",
    "        :param lstm_hidden: [batch_size, num_layers * num_directions, n_hidden]\n",
    "        :return: [batch_size, n_hidden]\n",
    "        '''\n",
    "        lstm_tmp_out = torch.chunk(lstm_out, 2, -1)\n",
    "        # h [batch_size, time_step, hidden_dims]\n",
    "        h = lstm_tmp_out[0] + lstm_tmp_out[1]\n",
    "        # h = lstm_out\n",
    "        # [batch_size, num_layers * num_directions, n_hidden]\n",
    "        lstm_hidden = torch.sum(lstm_hidden, dim=1)\n",
    "        # [batch_size, 1, n_hidden]\n",
    "        lstm_hidden = lstm_hidden.unsqueeze(1)\n",
    "        # atten_w [batch_size, 1, hidden_dims]\n",
    "        atten_w = self.attention_layer(lstm_hidden)\n",
    "        # m [batch_size, time_step, hidden_dims]\n",
    "        m = nn.Tanh()(h)\n",
    "        # atten_context [batch_size, 1, time_step]\n",
    "        atten_context = torch.bmm(atten_w, m.transpose(1, 2))\n",
    "        # softmax_w [batch_size, 1, time_step]\n",
    "        softmax_w = F.softmax(atten_context, dim=-1)\n",
    "        # context [batch_size, 1, hidden_dims]\n",
    "        context = torch.bmm(softmax_w, h)\n",
    "        result = context.squeeze(1)\n",
    "        return result\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x : [len_seq, batch_size, embedding_dim]\n",
    "        x = x.permute(1, 0, 2)\n",
    "        # x = self.ln1(x)\n",
    "        output, (final_hidden_state, _) = self.lstm_net(x)\n",
    "        # output : [batch_size, len_seq, n_hidden * 2]\n",
    "        output = output.permute(1, 0, 2)\n",
    "        # final_hidden_state : [batch_size, num_layers * num_directions, n_hidden]\n",
    "        final_hidden_state = final_hidden_state.permute(1, 0, 2)\n",
    "        # final_hidden_state = torch.mean(final_hidden_state, dim=0, keepdim=True)\n",
    "        # atten_out = self.attention_net(output, final_hidden_state)\n",
    "        atten_out = self.attention_net_with_w(output, final_hidden_state)\n",
    "        # atten_out = self.ln2(atten_out)\n",
    "        return self.fc_out(atten_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'num_classes': 2,\n",
    "    'dropout': 0.5,\n",
    "    'rnn_layers': 2,\n",
    "    'embedding_size': 1024,\n",
    "    'batch_size': 4,\n",
    "    'epochs': 50,\n",
    "    'learning_rate': 4e-5,\n",
    "    'hidden_dims': 128,\n",
    "    'bidirectional': True,\n",
    "    'cuda': False,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TextBiLSTM(config)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)  # Move model to GPU\n",
    "\n",
    "# Define optimizer and loss function\n",
    "optimizer = optim.AdamW(model.parameters(), lr=config['learning_rate'])\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function\n",
    "\n",
    "def train(epoch, train_loader,val_loader,best_accuracy):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        # Get sequence lengths (for packing)\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "        target = target.squeeze() \n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        \n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        pred = output.argmax(dim=1, keepdim=True)\n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    \n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    accuracy = correct / len(train_loader.dataset)\n",
    "    \n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    val_correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in val_loader:\n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "            target = target.squeeze()\n",
    "            \n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            val_loss += loss.item()\n",
    "            \n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            val_correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    val_accuracy = val_correct / len(val_loader.dataset)\n",
    "\n",
    "    print(f\"Train Epoch: {epoch}, Loss: {avg_loss:.4f}, Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Validation Loss: {avg_val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}\")\n",
    "\n",
    "    if val_accuracy > best_accuracy:\n",
    "        best_accuracy = val_accuracy\n",
    "        torch.save(model.state_dict(), '/mnt/sd1/jhansi/interns/chaithra/MS/sal_project/Classification/Models/text_best_model_2.pth')  # Save the best model\n",
    "    return best_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_69422/2750943036.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return self.text_features[idx], torch.tensor(self.labels[idx], dtype=torch.long)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1, Loss: 0.6945, Accuracy: 0.4797\n",
      "Validation Loss: 0.6976, Validation Accuracy: 0.4000\n",
      "Best model saved with accuracy: 0.4000\n",
      "Train Epoch: 2, Loss: 0.6924, Accuracy: 0.4932\n",
      "Validation Loss: 0.6993, Validation Accuracy: 0.4000\n",
      "Best model saved with accuracy: 0.4000\n",
      "Train Epoch: 3, Loss: 0.6934, Accuracy: 0.5068\n",
      "Validation Loss: 0.6954, Validation Accuracy: 0.4000\n",
      "Best model saved with accuracy: 0.4000\n",
      "Train Epoch: 4, Loss: 0.6914, Accuracy: 0.5541\n",
      "Validation Loss: 0.6967, Validation Accuracy: 0.4000\n",
      "Best model saved with accuracy: 0.4000\n",
      "Train Epoch: 5, Loss: 0.6937, Accuracy: 0.4932\n",
      "Validation Loss: 0.7028, Validation Accuracy: 0.4000\n",
      "Best model saved with accuracy: 0.4000\n",
      "Train Epoch: 6, Loss: 0.6889, Accuracy: 0.5135\n",
      "Validation Loss: 0.6996, Validation Accuracy: 0.4000\n",
      "Best model saved with accuracy: 0.4000\n",
      "Train Epoch: 7, Loss: 0.6903, Accuracy: 0.5541\n",
      "Validation Loss: 0.6950, Validation Accuracy: 0.3333\n",
      "Best model saved with accuracy: 0.4000\n",
      "Train Epoch: 8, Loss: 0.6845, Accuracy: 0.6216\n",
      "Validation Loss: 0.6951, Validation Accuracy: 0.3333\n",
      "Best model saved with accuracy: 0.4000\n",
      "Train Epoch: 9, Loss: 0.6857, Accuracy: 0.5473\n",
      "Validation Loss: 0.7003, Validation Accuracy: 0.4000\n",
      "Best model saved with accuracy: 0.4000\n",
      "Train Epoch: 10, Loss: 0.6848, Accuracy: 0.5338\n",
      "Validation Loss: 0.7033, Validation Accuracy: 0.4000\n",
      "Best model saved with accuracy: 0.4000\n",
      "Train Epoch: 11, Loss: 0.6821, Accuracy: 0.5811\n",
      "Validation Loss: 0.6894, Validation Accuracy: 0.5000\n",
      "Best model saved with accuracy: 0.5000\n",
      "Train Epoch: 12, Loss: 0.6757, Accuracy: 0.6284\n",
      "Validation Loss: 0.7049, Validation Accuracy: 0.3333\n",
      "Best model saved with accuracy: 0.5000\n",
      "Train Epoch: 13, Loss: 0.6672, Accuracy: 0.6351\n",
      "Validation Loss: 0.6844, Validation Accuracy: 0.5333\n",
      "Best model saved with accuracy: 0.5333\n",
      "Train Epoch: 14, Loss: 0.6571, Accuracy: 0.5946\n",
      "Validation Loss: 0.6744, Validation Accuracy: 0.5333\n",
      "Best model saved with accuracy: 0.5333\n",
      "Train Epoch: 15, Loss: 0.6463, Accuracy: 0.6689\n",
      "Validation Loss: 0.7216, Validation Accuracy: 0.3667\n",
      "Best model saved with accuracy: 0.5333\n",
      "Train Epoch: 16, Loss: 0.6261, Accuracy: 0.6892\n",
      "Validation Loss: 0.6412, Validation Accuracy: 0.6333\n",
      "Best model saved with accuracy: 0.6333\n",
      "Train Epoch: 17, Loss: 0.5986, Accuracy: 0.7230\n",
      "Validation Loss: 0.6386, Validation Accuracy: 0.6667\n",
      "Best model saved with accuracy: 0.6667\n",
      "Train Epoch: 18, Loss: 0.5627, Accuracy: 0.7500\n",
      "Validation Loss: 0.6196, Validation Accuracy: 0.6333\n",
      "Best model saved with accuracy: 0.6667\n",
      "Train Epoch: 19, Loss: 0.5295, Accuracy: 0.7703\n",
      "Validation Loss: 0.5959, Validation Accuracy: 0.7000\n",
      "Best model saved with accuracy: 0.7000\n",
      "Train Epoch: 20, Loss: 0.5059, Accuracy: 0.7635\n",
      "Validation Loss: 0.5877, Validation Accuracy: 0.7000\n",
      "Best model saved with accuracy: 0.7000\n",
      "Train Epoch: 21, Loss: 0.4697, Accuracy: 0.8716\n",
      "Validation Loss: 0.5732, Validation Accuracy: 0.7333\n",
      "Best model saved with accuracy: 0.7333\n",
      "Train Epoch: 22, Loss: 0.4236, Accuracy: 0.9257\n",
      "Validation Loss: 0.5668, Validation Accuracy: 0.7000\n",
      "Best model saved with accuracy: 0.7333\n",
      "Train Epoch: 23, Loss: 0.4141, Accuracy: 0.9054\n",
      "Validation Loss: 0.5874, Validation Accuracy: 0.7000\n",
      "Best model saved with accuracy: 0.7333\n",
      "Train Epoch: 24, Loss: 0.3933, Accuracy: 0.9257\n",
      "Validation Loss: 0.6385, Validation Accuracy: 0.6333\n",
      "Best model saved with accuracy: 0.7333\n",
      "Train Epoch: 25, Loss: 0.3819, Accuracy: 0.9459\n",
      "Validation Loss: 0.6556, Validation Accuracy: 0.6333\n",
      "Best model saved with accuracy: 0.7333\n",
      "Train Epoch: 26, Loss: 0.3621, Accuracy: 0.9662\n",
      "Validation Loss: 0.5521, Validation Accuracy: 0.7333\n",
      "Best model saved with accuracy: 0.7333\n",
      "Train Epoch: 27, Loss: 0.3560, Accuracy: 0.9730\n",
      "Validation Loss: 0.5448, Validation Accuracy: 0.7667\n",
      "Best model saved with accuracy: 0.7667\n",
      "Train Epoch: 28, Loss: 0.3671, Accuracy: 0.9392\n",
      "Validation Loss: 0.5519, Validation Accuracy: 0.7667\n",
      "Best model saved with accuracy: 0.7667\n",
      "Train Epoch: 29, Loss: 0.3527, Accuracy: 0.9730\n",
      "Validation Loss: 0.5684, Validation Accuracy: 0.7333\n",
      "Best model saved with accuracy: 0.7667\n",
      "Train Epoch: 30, Loss: 0.3867, Accuracy: 0.9257\n",
      "Validation Loss: 0.5885, Validation Accuracy: 0.7000\n",
      "Best model saved with accuracy: 0.7667\n",
      "Train Epoch: 31, Loss: 0.3431, Accuracy: 0.9730\n",
      "Validation Loss: 0.6052, Validation Accuracy: 0.6667\n",
      "Best model saved with accuracy: 0.7667\n",
      "Train Epoch: 32, Loss: 0.3409, Accuracy: 0.9797\n",
      "Validation Loss: 0.5559, Validation Accuracy: 0.7667\n",
      "Best model saved with accuracy: 0.7667\n",
      "Train Epoch: 33, Loss: 0.3462, Accuracy: 0.9730\n",
      "Validation Loss: 0.5857, Validation Accuracy: 0.7000\n",
      "Best model saved with accuracy: 0.7667\n",
      "Train Epoch: 34, Loss: 0.3240, Accuracy: 0.9932\n",
      "Validation Loss: 0.5774, Validation Accuracy: 0.7000\n",
      "Best model saved with accuracy: 0.7667\n",
      "Train Epoch: 35, Loss: 0.3227, Accuracy: 0.9932\n",
      "Validation Loss: 0.5938, Validation Accuracy: 0.7000\n",
      "Best model saved with accuracy: 0.7667\n",
      "Train Epoch: 36, Loss: 0.3222, Accuracy: 0.9932\n",
      "Validation Loss: 0.5775, Validation Accuracy: 0.7000\n",
      "Best model saved with accuracy: 0.7667\n",
      "Train Epoch: 37, Loss: 0.3226, Accuracy: 0.9932\n",
      "Validation Loss: 0.6130, Validation Accuracy: 0.7000\n",
      "Best model saved with accuracy: 0.7667\n",
      "Train Epoch: 38, Loss: 0.3319, Accuracy: 0.9932\n",
      "Validation Loss: 0.6181, Validation Accuracy: 0.6667\n",
      "Best model saved with accuracy: 0.7667\n",
      "Train Epoch: 39, Loss: 0.3298, Accuracy: 0.9865\n",
      "Validation Loss: 0.6544, Validation Accuracy: 0.6333\n",
      "Best model saved with accuracy: 0.7667\n",
      "Train Epoch: 40, Loss: 0.3407, Accuracy: 0.9730\n",
      "Validation Loss: 0.6112, Validation Accuracy: 0.7000\n",
      "Best model saved with accuracy: 0.7667\n",
      "Train Epoch: 41, Loss: 0.4413, Accuracy: 0.8581\n",
      "Validation Loss: 0.6685, Validation Accuracy: 0.6333\n",
      "Best model saved with accuracy: 0.7667\n",
      "Train Epoch: 42, Loss: 0.3406, Accuracy: 0.9797\n",
      "Validation Loss: 0.6104, Validation Accuracy: 0.7000\n",
      "Best model saved with accuracy: 0.7667\n",
      "Train Epoch: 43, Loss: 0.3426, Accuracy: 0.9662\n",
      "Validation Loss: 0.5662, Validation Accuracy: 0.7333\n",
      "Best model saved with accuracy: 0.7667\n",
      "Train Epoch: 44, Loss: 0.3273, Accuracy: 0.9865\n",
      "Validation Loss: 0.5537, Validation Accuracy: 0.7333\n",
      "Best model saved with accuracy: 0.7667\n",
      "Train Epoch: 45, Loss: 0.3218, Accuracy: 1.0000\n",
      "Validation Loss: 0.6060, Validation Accuracy: 0.7000\n",
      "Best model saved with accuracy: 0.7667\n",
      "Train Epoch: 46, Loss: 0.3214, Accuracy: 0.9932\n",
      "Validation Loss: 0.5990, Validation Accuracy: 0.7000\n",
      "Best model saved with accuracy: 0.7667\n",
      "Train Epoch: 47, Loss: 0.3158, Accuracy: 1.0000\n",
      "Validation Loss: 0.6004, Validation Accuracy: 0.7000\n",
      "Best model saved with accuracy: 0.7667\n",
      "Train Epoch: 48, Loss: 0.3150, Accuracy: 1.0000\n",
      "Validation Loss: 0.5984, Validation Accuracy: 0.7000\n",
      "Best model saved with accuracy: 0.7667\n",
      "Train Epoch: 49, Loss: 0.3148, Accuracy: 1.0000\n",
      "Validation Loss: 0.6013, Validation Accuracy: 0.7000\n",
      "Best model saved with accuracy: 0.7667\n",
      "Train Epoch: 50, Loss: 0.3146, Accuracy: 1.0000\n",
      "Validation Loss: 0.6005, Validation Accuracy: 0.7000\n",
      "Best model saved with accuracy: 0.7667\n"
     ]
    }
   ],
   "source": [
    "best_accuracy=0.0\n",
    "for epoch in range(1, config['epochs'] + 1):\n",
    "    best_accuracy=train(epoch, train_loader,test_loader,best_accuracy)\n",
    "    print(f\"Best model saved with accuracy: {best_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, confusion_matrix,precision_score,recall_score\n",
    "\n",
    "# Evaluation function\n",
    "def evaluate(test_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total_loss = 0.0  \n",
    "    total=0\n",
    "    all_preds = []  # To store all predictions\n",
    "    all_targets = []  # To store all true labels\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "            target = target.squeeze()\n",
    "            \n",
    "            output = model(data)\n",
    "            \n",
    "            total += target.size(0)\n",
    "            loss = criterion(output, target)\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "            \n",
    "            all_preds.extend(pred.cpu().numpy().flatten())\n",
    "            all_targets.extend(target.cpu().numpy().flatten())\n",
    "            \n",
    "        accuracy = correct / total\n",
    "        average_loss = total_loss / len(test_loader)\n",
    "        \n",
    "        results_df = pd.DataFrame({\n",
    "        'Predicted': all_preds,\n",
    "        'Target': all_targets\n",
    "        })\n",
    "    \n",
    "        #print(\"\\nPredicted vs Target:\")\n",
    "        #print(results_df)\n",
    "        \n",
    "        f1 = f1_score(all_targets, all_preds, average='weighted')\n",
    "        cm = confusion_matrix(all_targets, all_preds)\n",
    "        precision = precision_score(all_targets, all_preds, average='weighted')\n",
    "        recall = recall_score(all_targets, all_preds, average='weighted')\n",
    "        \n",
    "    print(f\"Loss: {average_loss:.4f}, Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}\")\n",
    "    \n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(cm)\n",
    "    return accuracy,results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.5448, Accuracy: 0.7667\n",
      "F1 Score: 0.7647, Precision: 0.7646, Recall: 0.7667\n",
      "Confusion Matrix:\n",
      "[[15  3]\n",
      " [ 4  8]]\n"
     ]
    }
   ],
   "source": [
    "########## data aug ########\n",
    "model.load_state_dict(torch.load('/mnt/sd1/jhansi/interns/chaithra/MS/sal_project/Classification/Models/text_best_model_2.pth', weights_only=True))\n",
    "model.eval()  # Set to evaluation mode\n",
    "\n",
    "# Evaluate on the test set\n",
    "accuracy = evaluate(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
